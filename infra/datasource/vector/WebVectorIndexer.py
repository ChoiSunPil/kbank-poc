# web_faiss_chroma.py
import os
import requests
from bs4 import BeautifulSoup
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from dotenv import load_dotenv

load_dotenv()

class WebVectorIndexer:
    def __init__(self, url: str, persist_dir: str = "chroma_faiss"):
        self.url = url
        self.persist_dir = persist_dir
        self.embeddings = OpenAIEmbeddings()
        self.vector_db = None
        self.raw_text = ""
        self.documents: list[Document] = []

    def crawl(self):
        print("ğŸŒ ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì¤‘...")
        res = requests.get(self.url)
        soup = BeautifulSoup(res.text, 'html.parser')
        self.raw_text = soup.get_text(separator='\n', strip=True)

    def prepare_documents(self):
        print("ğŸ“„ ë¬¸ì„œë¡œ ë³€í™˜ ì¤‘...")
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = splitter.split_text(self.raw_text)
        self.documents = [
            Document(page_content=chunk, metadata={"source": self.url})
            for chunk in chunks
        ]

    def build_vector_db(self):
        print("ğŸ§  ë²¡í„° DB ìƒì„± ì¤‘...")
        self.vector_db = Chroma.from_documents(
            documents=self.documents,
            embedding=self.embeddings,
            persist_directory=self.persist_dir
        )

    def search(self, query: str, top_k: int = 3):
        if not self.vector_db:
            raise RuntimeError("â— ë²¡í„° DBê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € build_vector_db()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
        print(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{query}'")
        results = self.vector_db.similarity_search(query, k=top_k)
        for i, doc in enumerate(results):
            print(f"\nğŸ”¹ ê²°ê³¼ {i+1}")
            print(doc.page_content)
            print(f"[ì¶œì²˜]: {doc.metadata.get('source')}")